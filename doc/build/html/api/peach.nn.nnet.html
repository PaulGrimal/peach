

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>peach.nn.nnet &mdash; Peach v0.3.1 documentation</title>
    <link rel="stylesheet" href="../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.3.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="Peach v0.3.1 documentation" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../index.html">Peach v0.3.1 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="module-peach.nn.nnet">
<span id="peach-nn-nnet"></span><h1>peach.nn.nnet<a class="headerlink" href="#module-peach.nn.nnet" title="Permalink to this headline">¶</a></h1>
<p>Basic topologies of neural networks.</p>
<p>This sub-package implements various neural network topologies, see the complete
list below. These topologies are implemented using the <tt class="docutils literal"><span class="pre">Layer</span></tt> class of the
<tt class="docutils literal"><span class="pre">base</span></tt> sub-package. Please, consult the documentation of that module for more
information on layers of neurons. The neural nets implemented here don&#8217;t derive
from the <tt class="docutils literal"><span class="pre">Layer</span></tt> class, instead, they have instance variables to take control
of them. Thus, there is no base class for networks. While subclassing the
classes of this module is usually safe, it is recomended that a new kind of
net is developed from the ground up.</p>
<dl class="class">
<dt id="peach.nn.nnet.FeedForward">
<em class="property">class </em><tt class="descclassname">peach.nn.nnet.</tt><tt class="descname">FeedForward</tt><big>(</big><em>layers</em>, <em>phi=&lt;class 'peach.nn.af.Linear'&gt;</em>, <em>lrule=&lt;class 'peach.nn.lrules.BackPropagation'&gt;</em>, <em>bias=False</em><big>)</big><a class="headerlink" href="#peach.nn.nnet.FeedForward" title="Permalink to this definition">¶</a></dt>
<dd><p>Classic completely connected neural network.</p>
<p>A feedforward neural network is implemented as a list of layers, each layer
being a <tt class="docutils literal"><span class="pre">Layer</span></tt> object (please consult the documentation on the <tt class="docutils literal"><span class="pre">base</span></tt>
module for more information on layers). The layers are completely connected,
which means that every neuron in one layers is connected to every other
neuron in the following layer.</p>
<p>There is a number of learning methods that are already implemented, but in
general, any learning class derived from <tt class="docutils literal"><span class="pre">FFLearning</span></tt> can be used. No
other kind of learning can be used. Please, consult the documentation on the
<tt class="docutils literal"><span class="pre">lrules</span></tt> (<em>learning rules</em>) module.</p>
<dl class="attribute">
<dt id="peach.nn.nnet.FeedForward.bias">
<tt class="descname">bias</tt><a class="headerlink" href="#peach.nn.nnet.FeedForward.bias" title="Permalink to this definition">¶</a></dt>
<dd><p>A tuple containing the bias of each layer. Not writable.</p>
</dd></dl>

<dl class="method">
<dt id="peach.nn.nnet.FeedForward.feed">
<tt class="descname">feed</tt><big>(</big><em>x</em>, <em>d</em><big>)</big><a class="headerlink" href="#peach.nn.nnet.FeedForward.feed" title="Permalink to this definition">¶</a></dt>
<dd><p>Feed the network and applies one example of the training set to the
network.</p>
<p>Using this method, one iteration of the learning procedure is made with
the neurons of this network. This method presents one example (not
necessarilly of a training set) and applies the learning rule over the
network. The learning rule is defined in the initialization of the
network, and some are implemented on the <tt class="docutils literal"><span class="pre">lrules</span></tt> method. New methods
can be created, consult the <tt class="docutils literal"><span class="pre">lrules</span></tt> documentation but, for
<tt class="docutils literal"><span class="pre">FeedForward</span></tt> instances, only <tt class="docutils literal"><span class="pre">FFLearning</span></tt> learning is allowed.</p>
<p>Also, notice that <em>this method feeds the network</em> before applying the
learning rule. Feeding the network has collateral effects, and some
properties change when this happens. Namely, the <tt class="docutils literal"><span class="pre">y</span></tt> property is set.
Please consult the <tt class="docutils literal"><span class="pre">__call__</span></tt> interface.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Parameters :</th><td class="field-body"><dl class="first docutils">
<dt>x</dt>
<dd><p class="first last">Input vector of the example. It should be a column vector of the
correct dimension, that is, the number of input neurons.</p>
</dd>
<dt>d</dt>
<dd><p class="first last">The desired answer of the network for this particular input vector.
Notice that the desired answer should have the same dimension of the
last layer of the network. This means that a desired answer should
be given for every output of the network.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field"><th class="field-name">Returns :</th><td class="field-body"><p class="first last">The error obtained by the network.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="peach.nn.nnet.FeedForward.learn">
<tt class="descname">learn</tt><big>(</big><em>x</em>, <em>d</em><big>)</big><a class="headerlink" href="#peach.nn.nnet.FeedForward.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies one example of the training set to the network.</p>
<p>Using this method, one iteration of the learning procedure is made with
the neurons of this network. This method presents one example (not
necessarilly of a training set) and applies the learning rule over the
network. The learning rule is defined in the initialization of the
network, and some are implemented on the <tt class="docutils literal"><span class="pre">lrules</span></tt> method. New methods
can be created, consult the <tt class="docutils literal"><span class="pre">lrules</span></tt> documentation but, for
<tt class="docutils literal"><span class="pre">FeedForward</span></tt> instances, only <tt class="docutils literal"><span class="pre">FFLearning</span></tt> learning is allowed.</p>
<p>Also, notice that <em>this method only applies the learning method!</em> The
network should be fed with the same input vector before trying to learn
anything first. Consult the <tt class="docutils literal"><span class="pre">feed</span></tt> and <tt class="docutils literal"><span class="pre">train</span></tt> methods below for
more ways to train a network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Parameters :</th><td class="field-body"><dl class="first docutils">
<dt>x</dt>
<dd><p class="first last">Input vector of the example. It should be a column vector of the
correct dimension, that is, the number of input neurons.</p>
</dd>
<dt>d</dt>
<dd><p class="first last">The desired answer of the network for this particular input vector.
Notice that the desired answer should have the same dimension of the
last layer of the network. This means that a desired answer should
be given for every output of the network.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field"><th class="field-name">Returns :</th><td class="field-body"><p class="first last">The error obtained by the network.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="peach.nn.nnet.FeedForward.nlayers">
<tt class="descname">nlayers</tt><a class="headerlink" href="#peach.nn.nnet.FeedForward.nlayers" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of layers of the neural network. Not writable.</p>
</dd></dl>

<dl class="attribute">
<dt id="peach.nn.nnet.FeedForward.phi">
<tt class="descname">phi</tt><a class="headerlink" href="#peach.nn.nnet.FeedForward.phi" title="Permalink to this definition">¶</a></dt>
<dd><p>Activation functions for every layer in the network. It is a list of
<tt class="docutils literal"><span class="pre">Activation</span></tt> objects, but can be set with only one function. In this case,
the same function is used for every layer.</p>
</dd></dl>

<dl class="method">
<dt id="peach.nn.nnet.FeedForward.train">
<tt class="descname">train</tt><big>(</big><em>train_set</em>, <em>imax=2000</em>, <em>emax=1e-05</em>, <em>randomize=False</em><big>)</big><a class="headerlink" href="#peach.nn.nnet.FeedForward.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Presents a training set to the network.</p>
<p>This method automatizes the training of the network. Given a training
set, the examples are shown to the network (possibly in a randomized
way). A maximum number of iterations or a maximum admitted error should
be given as a stop condition.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Parameters :</th><td class="field-body"><dl class="first last docutils">
<dt>train_set</dt>
<dd><p class="first last">The training set is a list of examples. It can have any size and can
contain repeated examples. In fact, the definition of the training
set is open. Each element of the training set, however, should be a
two-tuple <tt class="docutils literal"><span class="pre">(x,</span> <span class="pre">d)</span></tt>, where <tt class="docutils literal"><span class="pre">x</span></tt> is the input vector, and <tt class="docutils literal"><span class="pre">d</span></tt> is
the desired response of the network for this particular input. See
the <tt class="docutils literal"><span class="pre">learn</span></tt> and <tt class="docutils literal"><span class="pre">feed</span></tt> for more information.</p>
</dd>
<dt>imax</dt>
<dd><p class="first last">The maximum number of iterations. Examples from the training set
will be presented to the network while this limit is not reached.
Defaults to 2000.</p>
</dd>
<dt>emax</dt>
<dd><p class="first last">The maximum admitted error. Examples from the training set will be
presented to the network until the error obtained is lower than this
limit. Defaults to 1e-5.</p>
</dd>
<dt>randomize</dt>
<dd><p class="first last">If this is <tt class="xref docutils literal"><span class="pre">True</span></tt>, then the examples are shown in a randomized
order. If <tt class="xref docutils literal"><span class="pre">False</span></tt>, then the examples are shown in the same order
that they appear in the <tt class="docutils literal"><span class="pre">train_set</span></tt> list. Defaults to <tt class="xref docutils literal"><span class="pre">False</span></tt>.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="peach.nn.nnet.FeedForward.y">
<tt class="descname">y</tt><a class="headerlink" href="#peach.nn.nnet.FeedForward.y" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of activation values for each neuron in the last layer of the
network, ie., the answer of the network. This property is available only
after the network is fed some input.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="peach.nn.nnet.GRNN">
<em class="property">class </em><tt class="descclassname">peach.nn.nnet.</tt><tt class="descname">GRNN</tt><big>(</big><em>sigma=0.1</em><big>)</big><a class="headerlink" href="#peach.nn.nnet.GRNN" title="Permalink to this definition">¶</a></dt>
<dd><p>GRNN is the implementation of General Regression Neural Network, a kind of
probabilistic neural network used in regression tasks.</p>
<dl class="method">
<dt id="peach.nn.nnet.GRNN.train">
<tt class="descname">train</tt><big>(</big><em>sampleInputs</em>, <em>targets</em><big>)</big><a class="headerlink" href="#peach.nn.nnet.GRNN.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Presents a training set to the network.</p>
<p>This method uses the sample inputs to set the size of network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Parameters :</th><td class="field-body"><dl class="first last docutils">
<dt>sampleInputs</dt>
<dd><p class="first last">Should be a list of numbers or a list of <tt class="docutils literal"><span class="pre">numpy.array</span></tt> to set the
sample inputs. These inputs are used to calculate the distance 
between prediction points.</p>
</dd>
<dt>targets</dt>
<dd><p class="first last">The target values of sample inputs. Should be a list of numbers.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="peach.nn.nnet.PNN">
<em class="property">class </em><tt class="descclassname">peach.nn.nnet.</tt><tt class="descname">PNN</tt><big>(</big><em>sigma=0.1</em><big>)</big><a class="headerlink" href="#peach.nn.nnet.PNN" title="Permalink to this definition">¶</a></dt>
<dd><p>PNN is the implementation of Probabilistic Neural Network, a network used
for classification tasks</p>
<dl class="method">
<dt id="peach.nn.nnet.PNN.train">
<tt class="descname">train</tt><big>(</big><em>trainSet</em><big>)</big><a class="headerlink" href="#peach.nn.nnet.PNN.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Presents a training set to the network.</p>
<p>This method uses the sample inputs to set the size of network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Parameters :</th><td class="field-body"><dl class="first last docutils">
<dt>train_set</dt>
<dd><p class="first last">The training set is a list of examples. It can have any size. In 
fact, the definition of the training set is open. Each element of 
the training set, however, should be a two-tuple <tt class="docutils literal"><span class="pre">(x,</span> <span class="pre">d)</span></tt>, where 
<tt class="docutils literal"><span class="pre">x</span></tt> is the input vector, and <tt class="docutils literal"><span class="pre">d</span></tt> is the desired response of the 
network for this particular input, i.e the category of <tt class="docutils literal"><span class="pre">x</span></tt> 
pattern.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="peach.nn.nnet.SOM">
<em class="property">class </em><tt class="descclassname">peach.nn.nnet.</tt><tt class="descname">SOM</tt><big>(</big><em>shape</em>, <em>lrule=&lt;class 'peach.nn.lrules.Competitive'&gt;</em><big>)</big><a class="headerlink" href="#peach.nn.nnet.SOM" title="Permalink to this definition">¶</a></dt>
<dd><p>A Self-Organizing Map (SOM).</p>
<p>A self-organizing map is a type of neural network that is trained via
unsupervised learning. In particular, the self-organizing map finds the
neuron closest to an input vector &#8211; this neuron is the winning neuron, and
it is the answer of the network. Thus, the SOM is usually used for
classification and pattern recognition.</p>
<p>The SOM is a single-layer network, so this class subclasses the <tt class="docutils literal"><span class="pre">Layer</span></tt>
class. But some of the properties of a <tt class="docutils literal"><span class="pre">Layer</span></tt> object are not available or
make no sense in this context.</p>
<dl class="method">
<dt id="peach.nn.nnet.SOM.feed">
<tt class="descname">feed</tt><big>(</big><em>x</em><big>)</big><a class="headerlink" href="#peach.nn.nnet.SOM.feed" title="Permalink to this definition">¶</a></dt>
<dd><p>Feed the network and applies one example of the training set to the
network.</p>
<p>Using this method, one iteration of the learning procedure is made with
the neurons of this network. This method presents one example (not
necessarilly of a training set) and applies the learning rule over the
network. The learning rule is defined in the initialization of the
network, and some are implemented on the <tt class="docutils literal"><span class="pre">lrules</span></tt> method. New methods
can be created, consult the <tt class="docutils literal"><span class="pre">lrules</span></tt> documentation but, for
<tt class="docutils literal"><span class="pre">SOM</span></tt> instances, only <tt class="docutils literal"><span class="pre">SOMLearning</span></tt> learning is allowed.</p>
<p>Also, notice that <em>this method feeds the network</em> before applying the
learning rule. Feeding the network has collateral effects, and some
properties change when this happens. Namely, the <tt class="docutils literal"><span class="pre">y</span></tt> property is set.
Please consult the <tt class="docutils literal"><span class="pre">__call__</span></tt> interface.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Parameters :</th><td class="field-body"><dl class="first docutils">
<dt>x</dt>
<dd><p class="first last">Input vector of the example. It should be a column vector of the
correct dimension, that is, the number of input neurons.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field"><th class="field-name">Returns :</th><td class="field-body"><p class="first last">The error obtained by the network.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="peach.nn.nnet.SOM.learn">
<tt class="descname">learn</tt><big>(</big><em>x</em><big>)</big><a class="headerlink" href="#peach.nn.nnet.SOM.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies one example of the training set to the network.</p>
<p>Using this method, one iteration of the learning procedure is made with
the neurons of this network. This method presents one example (not
necessarilly of a training set) and applies the learning rule over the
network. The learning rule is defined in the initialization of the
network, and some are implemented on the <tt class="docutils literal"><span class="pre">lrules</span></tt> method. New methods
can be created, consult the <tt class="docutils literal"><span class="pre">lrules</span></tt> documentation but, for
<tt class="docutils literal"><span class="pre">SOM</span></tt> instances, only <tt class="docutils literal"><span class="pre">SOMLearning</span></tt> learning is allowed.</p>
<p>Also, notice that <em>this method only applies the learning method!</em> The
network should be fed with the same input vector before trying to learn
anything first. Consult the <tt class="docutils literal"><span class="pre">feed</span></tt> and <tt class="docutils literal"><span class="pre">train</span></tt> methods below for
more ways to train a network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Parameters :</th><td class="field-body"><dl class="first docutils">
<dt>x</dt>
<dd><p class="first last">Input vector of the example. It should be a column vector of the
correct dimension, that is, the number of input neurons.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field"><th class="field-name">Returns :</th><td class="field-body"><p class="first last">The error obtained by the network.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="peach.nn.nnet.SOM.train">
<tt class="descname">train</tt><big>(</big><em>train_set</em>, <em>imax=2000</em>, <em>emax=1e-05</em>, <em>randomize=False</em><big>)</big><a class="headerlink" href="#peach.nn.nnet.SOM.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Presents a training set to the network.</p>
<p>This method automatizes the training of the network. Given a training
set, the examples are shown to the network (possibly in a randomized
way). A maximum number of iterations or a maximum admitted error should
be given as a stop condition.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Parameters :</th><td class="field-body"><dl class="first last docutils">
<dt>train_set</dt>
<dd><p class="first last">The training set is a list of examples. It can have any size and can
contain repeated examples. In fact, the definition of the training
set is open. Each element of the training set, however, should be a
input vector of the correct dimensions, See the <tt class="docutils literal"><span class="pre">learn</span></tt> and
<tt class="docutils literal"><span class="pre">feed</span></tt> for more information.</p>
</dd>
<dt>imax</dt>
<dd><p class="first last">The maximum number of iterations. Examples from the training set
will be presented to the network while this limit is not reached.
Defaults to 2000.</p>
</dd>
<dt>emax</dt>
<dd><p class="first last">The maximum admitted error. Examples from the training set will be
presented to the network until the error obtained is lower than this
limit. Defaults to 1e-5.</p>
</dd>
<dt>randomize</dt>
<dd><p class="first last">If this is <tt class="xref docutils literal"><span class="pre">True</span></tt>, then the examples are shown in a randomized
order. If <tt class="xref docutils literal"><span class="pre">False</span></tt>, then the examples are shown in the same order
that they appear in the <tt class="docutils literal"><span class="pre">train_set</span></tt> list. Defaults to <tt class="xref docutils literal"><span class="pre">False</span></tt>.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="peach.nn.nnet.SOM.y">
<tt class="descname">y</tt><a class="headerlink" href="#peach.nn.nnet.SOM.y" title="Permalink to this definition">¶</a></dt>
<dd><p>The winning neuron for a given input, the answer of the network. This
property is available only after the network is fed some input.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="peach.nn.nnet.randn">
<tt class="descclassname">peach.nn.nnet.</tt><tt class="descname">randn</tt><big>(</big><big>)</big><a class="headerlink" href="#peach.nn.nnet.randn" title="Permalink to this definition">¶</a></dt>
<dd><p>randn([d1, ..., dn])</p>
<p>Return a sample (or samples) from the &#8220;standard normal&#8221; distribution.</p>
<p>If positive, int_like or int-convertible arguments are provided,
<cite>randn</cite> generates an array of shape <tt class="docutils literal"><span class="pre">(d1,</span> <span class="pre">...,</span> <span class="pre">dn)</span></tt>, filled
with random floats sampled from a univariate &#8220;normal&#8221; (Gaussian)
distribution of mean 0 and variance 1 (if any of the <span class="math">d_i</span> are
floats, they are first converted to integers by truncation). A single
float randomly sampled from the distribution is returned if no
argument is provided.</p>
<p>This is a convenience function.  If you want an interface that takes a
tuple as the first argument, use <cite>numpy.random.standard_normal</cite> instead.</p>
<dl class="docutils">
<dt>d1, ..., dn <span class="classifier-delimiter">:</span> <span class="classifier"><cite>n</cite> ints, optional</span></dt>
<dd>The dimensions of the returned array, should be all positive.</dd>
</dl>
<dl class="docutils">
<dt>Z <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or float</span></dt>
<dd>A <tt class="docutils literal"><span class="pre">(d1,</span> <span class="pre">...,</span> <span class="pre">dn)</span></tt>-shaped array of floating-point samples from
the standard normal distribution, or a single such float if
no parameters were supplied.</dd>
</dl>
<p>random.standard_normal : Similar, but takes a tuple as its argument.</p>
<p>For random samples from <span class="math">N(\mu, \sigma^2)</span>, use:</p>
<p><tt class="docutils literal"><span class="pre">sigma</span> <span class="pre">*</span> <span class="pre">np.random.randn(...)</span> <span class="pre">+</span> <span class="pre">mu</span></tt></p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span>
<span class="go">2.1923875335537315 #random</span>
</pre></div>
</div>
<p>Two-by-four array of samples from N(3, 6.25):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="mf">2.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="o">+</span> <span class="mi">3</span>
<span class="go">array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],  #random</span>
<span class="go">       [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]]) #random</span>
</pre></div>
</div>
</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/api/peach.nn.nnet.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../index.html">Peach v0.3.1 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2009, José Alexandre Nalon.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.0.8.
    </div>
  </body>
</html>


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>peach.nn.rbfn &mdash; Peach v0.3.1 documentation</title>
    <link rel="stylesheet" href="../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.3.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="Peach v0.3.1 documentation" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../index.html">Peach v0.3.1 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="module-peach.nn.rbfn">
<span id="peach-nn-rbfn"></span><h1>peach.nn.rbfn<a class="headerlink" href="#module-peach.nn.rbfn" title="Permalink to this headline">¶</a></h1>
<p>Radial Basis Function Networks</p>
<p>This sub-package implements the basic behaviour of radial basis function
networks. This is a two-layer neural network that works as a universal function
approximator. The activation functions of the first layer are radial basis
functions (RBFs), that are symmetric around the origin, that is, the value of
this kind of function depends only on the distance of the evaluated point to the
origin. The second layer has only one neuron with linear activation, that is, it
only combines the inputs of the first layer.</p>
<p>The training of this kind of network, while it can be done using a traditional
optimization technique such as gradient descent, is usually made in two steps.
In the first step, the position of the centers and the width of the RBFs are
computed. In the second step, the weights of the second layer are adapted. In
this module, the RBFN architecture is implemented, allowing training of the
second layer. Centers must be supplied, but they can be easily found from the
training set using algorithms such as K-Means (the one traditionally used),
SOMs or Fuzzy C-Means.</p>
<dl class="class">
<dt id="peach.nn.rbfn.RBFN">
<em class="property">class </em><tt class="descclassname">peach.nn.rbfn.</tt><tt class="descname">RBFN</tt><big>(</big><em>c</em>, <em>phi=&lt;class 'peach.nn.af.Gaussian'&gt;</em>, <em>phi2=&lt;class 'peach.nn.af.Linear'&gt;</em><big>)</big><a class="headerlink" href="#peach.nn.rbfn.RBFN" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="peach.nn.rbfn.RBFN.feed">
<tt class="descname">feed</tt><big>(</big><em>x</em>, <em>d</em><big>)</big><a class="headerlink" href="#peach.nn.rbfn.RBFN.feed" title="Permalink to this definition">¶</a></dt>
<dd><p>Feed the network and applies one example of the training set to the
network. This adapts only the synaptic weights in the second layer of
the RBFN.</p>
<p>Using this method, one iteration of the learning procedure is made with
the neurons of this network. This method presents one example (not
necessarilly from a training set) and applies the learning rule over the
network. The learning rule is defined in the initialization of the
network, and some are implemented on the <tt class="docutils literal"><span class="pre">lrules</span></tt> method. New methods
can be created, consult the <tt class="docutils literal"><span class="pre">lrules</span></tt> documentation but, for the second
layer of a <tt class="docutils literal"><span class="pre">RBFN</span></tt>, only <tt class="docutils literal"><span class="pre">FFLearning</span></tt> learning is allowed.</p>
<p>Also, notice that <em>this method feeds the network</em> before applying the
learning rule. Feeding the network has collateral effects, and some
properties change when this happens. Namely, the <tt class="docutils literal"><span class="pre">y</span></tt> property is set.
Please consult the <tt class="docutils literal"><span class="pre">__call__</span></tt> interface.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Parameters :</th><td class="field-body"><dl class="first docutils">
<dt>x</dt>
<dd><p class="first last">Input vector of the example. It should be a column vector of the
correct dimension, that is, the number of input neurons.</p>
</dd>
<dt>d</dt>
<dd><p class="first last">The desired answer of the network for this particular input vector.
Notice that the desired answer should have the same dimension of the
last layer of the network. This means that a desired answer should
be given for every output of the network.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field"><th class="field-name">Returns :</th><td class="field-body"><p class="first last">The error obtained by the network.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="peach.nn.rbfn.RBFN.learn">
<tt class="descname">learn</tt><big>(</big><em>x</em>, <em>d</em><big>)</big><a class="headerlink" href="#peach.nn.rbfn.RBFN.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies one example of the training set to the network.</p>
<p>Using this method, one iteration of the learning procedure is executed
for the second layer of the network. This method presents one example
(not necessarilly from a training set) and applies the learning rule
over the layer. The learning rule is defined in the initialization of
the network, and some are implemented on the <tt class="docutils literal"><span class="pre">lrules</span></tt> method. New
methods can be created, consult the <tt class="docutils literal"><span class="pre">lrules</span></tt> documentation but, for
the second layer of a <tt class="docutils literal"><span class="pre">RBFN''</span> <span class="pre">instance,</span> <span class="pre">only</span> <span class="pre">``FFLearning</span></tt> learning is
allowed.</p>
<p>Also, notice that <em>this method only applies the learning method!</em> The
network should be fed with the same input vector before trying to learn
anything first. Consult the <tt class="docutils literal"><span class="pre">feed</span></tt> and <tt class="docutils literal"><span class="pre">train</span></tt> methods below for
more ways to train a network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Parameters :</th><td class="field-body"><dl class="first docutils">
<dt>x</dt>
<dd><p class="first last">Input vector of the example. It should be a column vector of the
correct dimension, that is, the number of input neurons.</p>
</dd>
<dt>d</dt>
<dd><p class="first last">The desired answer of the network for this particular input vector.
Notice that the desired answer should have the same dimension of the
last layer of the network. This means that a desired answer should
be given for every output of the network.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field"><th class="field-name">Returns :</th><td class="field-body"><p class="first last">The error obtained by the network.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="peach.nn.rbfn.RBFN.phi">
<tt class="descname">phi</tt><a class="headerlink" href="#peach.nn.rbfn.RBFN.phi" title="Permalink to this definition">¶</a></dt>
<dd><p>The radial basis function. It can be set with a <tt class="docutils literal"><span class="pre">RadialBasis</span></tt> instance
or a standard Python function. If a standard function is given, it must
receive a real value and return a real value that is the activation value of
the neuron. In that case, it is adjusted to work accordingly with the
internals of the layer.</p>
</dd></dl>

<dl class="attribute">
<dt id="peach.nn.rbfn.RBFN.phi2">
<tt class="descname">phi2</tt><a class="headerlink" href="#peach.nn.rbfn.RBFN.phi2" title="Permalink to this definition">¶</a></dt>
<dd><p>The activation function for the second layer. It can be set with an
<tt class="docutils literal"><span class="pre">Activation</span></tt> instance or a standard Python function. If a standard
function is given, it must receive a real value and return a real value that
is the activation value of the neuron. In that case, it is adjusted to work
accordingly with the internals of the layer.</p>
</dd></dl>

<dl class="method">
<dt id="peach.nn.rbfn.RBFN.train">
<tt class="descname">train</tt><big>(</big><em>train_set</em>, <em>imax=2000</em>, <em>emax=1e-05</em>, <em>randomize=False</em><big>)</big><a class="headerlink" href="#peach.nn.rbfn.RBFN.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Presents a training set to the network.</p>
<p>This method automatizes the training of the network. Given a training
set, the examples are shown to the network (possibly in a randomized
way). A maximum number of iterations or a maximum admitted error should
be given as a stop condition.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Parameters :</th><td class="field-body"><dl class="first last docutils">
<dt>train_set</dt>
<dd><p class="first last">The training set is a list of examples. It can have any size and can
contain repeated examples. In fact, the definition of the training
set is open. Each element of the training set, however, should be a
two-tuple <tt class="docutils literal"><span class="pre">(x,</span> <span class="pre">d)</span></tt>, where <tt class="docutils literal"><span class="pre">x</span></tt> is the input vector, and <tt class="docutils literal"><span class="pre">d</span></tt> is
the desired response of the network for this particular input. See
the <tt class="docutils literal"><span class="pre">learn</span></tt> and <tt class="docutils literal"><span class="pre">feed</span></tt> for more information.</p>
</dd>
<dt>imax</dt>
<dd><p class="first last">The maximum number of iterations. Examples from the training set
will be presented to the network while this limit is not reached.
Defaults to 2000.</p>
</dd>
<dt>emax</dt>
<dd><p class="first last">The maximum admitted error. Examples from the training set will be
presented to the network until the error obtained is lower than this
limit. Defaults to 1e-5.</p>
</dd>
<dt>randomize</dt>
<dd><p class="first last">If this is <tt class="xref docutils literal"><span class="pre">True</span></tt>, then the examples are shown in a randomized
order. If <tt class="xref docutils literal"><span class="pre">False</span></tt>, then the examples are shown in the same order
that they appear in the <tt class="docutils literal"><span class="pre">train_set</span></tt> list. Defaults to <tt class="xref docutils literal"><span class="pre">False</span></tt>.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="peach.nn.rbfn.RBFN.weights">
<tt class="descname">weights</tt><a class="headerlink" href="#peach.nn.rbfn.RBFN.weights" title="Permalink to this definition">¶</a></dt>
<dd><p>A <tt class="docutils literal"><span class="pre">numpy</span></tt> array containing the synaptic weights of the second layer of
the network. It is writable, but the new weight array must be the same shape
of the neuron, or an exception is raised.</p>
</dd></dl>

<dl class="attribute">
<dt id="peach.nn.rbfn.RBFN.width">
<tt class="descname">width</tt><a class="headerlink" href="#peach.nn.rbfn.RBFN.width" title="Permalink to this definition">¶</a></dt>
<dd><p>The computed width of the RBFs. This property can be read and written. If
a single value is written, then it is used for every center. If a vector of
values is supplied, then it must be one for each center.</p>
</dd></dl>

<dl class="attribute">
<dt id="peach.nn.rbfn.RBFN.y">
<tt class="descname">y</tt><a class="headerlink" href="#peach.nn.rbfn.RBFN.y" title="Permalink to this definition">¶</a></dt>
<dd><p>The activation value for the second layer of the network, ie., the answer
of the network. This property is available only after the network is fed
some input.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="peach.nn.rbfn.randn">
<tt class="descclassname">peach.nn.rbfn.</tt><tt class="descname">randn</tt><big>(</big><big>)</big><a class="headerlink" href="#peach.nn.rbfn.randn" title="Permalink to this definition">¶</a></dt>
<dd><p>randn([d1, ..., dn])</p>
<p>Return a sample (or samples) from the &#8220;standard normal&#8221; distribution.</p>
<p>If positive, int_like or int-convertible arguments are provided,
<cite>randn</cite> generates an array of shape <tt class="docutils literal"><span class="pre">(d1,</span> <span class="pre">...,</span> <span class="pre">dn)</span></tt>, filled
with random floats sampled from a univariate &#8220;normal&#8221; (Gaussian)
distribution of mean 0 and variance 1 (if any of the <span class="math">d_i</span> are
floats, they are first converted to integers by truncation). A single
float randomly sampled from the distribution is returned if no
argument is provided.</p>
<p>This is a convenience function.  If you want an interface that takes a
tuple as the first argument, use <cite>numpy.random.standard_normal</cite> instead.</p>
<dl class="docutils">
<dt>d1, ..., dn <span class="classifier-delimiter">:</span> <span class="classifier"><cite>n</cite> ints, optional</span></dt>
<dd>The dimensions of the returned array, should be all positive.</dd>
</dl>
<dl class="docutils">
<dt>Z <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or float</span></dt>
<dd>A <tt class="docutils literal"><span class="pre">(d1,</span> <span class="pre">...,</span> <span class="pre">dn)</span></tt>-shaped array of floating-point samples from
the standard normal distribution, or a single such float if
no parameters were supplied.</dd>
</dl>
<p>random.standard_normal : Similar, but takes a tuple as its argument.</p>
<p>For random samples from <span class="math">N(\mu, \sigma^2)</span>, use:</p>
<p><tt class="docutils literal"><span class="pre">sigma</span> <span class="pre">*</span> <span class="pre">np.random.randn(...)</span> <span class="pre">+</span> <span class="pre">mu</span></tt></p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span>
<span class="go">2.1923875335537315 #random</span>
</pre></div>
</div>
<p>Two-by-four array of samples from N(3, 6.25):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="mf">2.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="o">+</span> <span class="mi">3</span>
<span class="go">array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],  #random</span>
<span class="go">       [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]]) #random</span>
</pre></div>
</div>
</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/api/peach.nn.rbfn.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../index.html">Peach v0.3.1 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2009, José Alexandre Nalon.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.0.8.
    </div>
  </body>
</html>
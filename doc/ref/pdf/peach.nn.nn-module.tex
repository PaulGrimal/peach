%
% API Documentation for Peach - Computational Intelligence for Python
% Module peach.nn.nn
%
% Generated by epydoc 3.0beta1
% [Mon Dec 21 08:51:37 2009]
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Module Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}|(}
\section{Module peach.nn.nn}

    \label{peach:nn:nn}

Basic topologies of neural networks.

This sub-package implements various neural network topologies, see the complete
list below. These topologies are implemented using the \texttt{Layer} class of the
\texttt{base} sub-package. Please, consult the documentation of that module for more
information on layers of neurons. The neural nets implemented here don't derive
from the \texttt{Layer} class, instead, they have instance variables to take control
of them. Thus, there is no base class for networks. While subclassing the
classes of this module is usually safe, it is recomended that a new kind of
net is developed from the ground up.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               Functions                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsection{Functions}

    \label{peach:nn:nn:randn}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.randn \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{randn}(\textit{d0}, \textit{d1}, \textit{dn}, \textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

Returns zero-mean, unit-variance Gaussian random numbers in an
array of shape (d0, d1, ..., dn).
\begin{description}
%[visit_definition_list_item]
\item[{Note:  This is a convenience function. If you want an}] %[visit_definition]

interface that takes a tuple as the first argument
use numpy.random.standard{\_}normal(shape{\_}tuple).

%[depart_definition]
%[depart_definition_list_item]
\end{description}
    \vspace{1ex}

    \end{boxedminipage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               Variables                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsection{Variables}

\begin{longtable}{|p{.30\textwidth}|p{.62\textwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright \_\-\_\-d\-o\-c\-\_\-\_\- & \raggedright \textbf{Value:} 
{\tt \texttt{...}}&\\
\cline{1-2}
\raggedright a\-r\-c\-t\-a\-n\- & \raggedright \textbf{Value:} 
{\tt {\textless}ufunc 'arctan'{\textgreater}}&\\
\cline{1-2}
\raggedright c\-o\-s\-h\- & \raggedright \textbf{Value:} 
{\tt {\textless}ufunc 'cosh'{\textgreater}}&\\
\cline{1-2}
\raggedright e\-x\-p\- & \raggedright \textbf{Value:} 
{\tt {\textless}ufunc 'exp'{\textgreater}}&\\
\cline{1-2}
\raggedright p\-i\- & \raggedright \textbf{Value:} 
{\tt 3.14159265359}&\\
\cline{1-2}
\raggedright t\-a\-n\-h\- & \raggedright \textbf{Value:} 
{\tt {\textless}ufunc 'tanh'{\textgreater}}&\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.FeedForward \textit{(class)}|(}
\subsection{Class FeedForward}

    \label{peach:nn:nn:FeedForward}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for list, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{list}\multirow{2}{\BCL}{list}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.nn.nn.FeedForward}}
\end{tabular}


Classic completely connected neural network.

A feedforward neural network is implemented as a list of layers, each layer
being a \texttt{Layer} object (please consult the documentation on the \texttt{base}
module for more information on layers). The layers are completely connected,
which means that every neuron in one layers is connected to every other
neuron in the following layer.

There is a number of learning methods that are already implemented, but in
general, any learning class derived from \texttt{FFLearning} can be used. No
other kind of learning can be used. Please, consult the documentation on the
\texttt{lrules} (\emph{learning rules}) module.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{layers}, \textit{phi}=\texttt{{\textless}class 'peach.nn.af.Linear'{\textgreater}}, \textit{lrule}=\texttt{{\textless}class 'peach.nn.lrules.BackPropagation'{\textgreater}}, \textit{bias}=\texttt{False})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

Initializes a feedforward neural network.

A feedforward network is implemented as a list of layers, completely
connected.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{xxxxxx}

          \item[layers]


A list of integers containing the shape of the network. The first
element of the list is the number of inputs of the network (or, as
somebody prefer, the number of input neurons); the number of outputs
is the number of neurons in the last layer. Thus, at least two
numbers should be given.
          \item[phi]


The activation functions to be used with each layer of the network.
Please consult the \texttt{Layer} documentation in the \texttt{base} module
for more information. This parameter can be a single function or a
list of functions. If only one function is given, then the same
function is used in every layer. If a list of functions is given,
then the layers use the functions in the sequence given. Note that
heterogeneous networks can be created that way. Defaults to
\texttt{Linear}.
          \item[lrule]


The learning rule used. Only \texttt{FFLearning} objects (instances of
the class or of the subclasses) are allowed. Defaults to
\texttt{BackPropagation}. Check the \texttt{lrules} documentation for more
information.
          \item[bias]


If \texttt{True}, then the neurons are biased.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

      \textbf{Return Value}
      \begin{quote}
\begin{alltt}
new list
\end{alltt}

      \end{quote}

    \vspace{1ex}

      Overrides: list.\_\_init\_\_

    \end{boxedminipage}

    \label{peach:nn:nn:FeedForward:__getnlayers}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.FeedForward \textit{(class)}!peach.nn.nn.FeedForward.\_\_getnlayers \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_getnlayers}(\textit{self})

    \end{boxedminipage}

    \label{peach:nn:nn:FeedForward:__getbias}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.FeedForward \textit{(class)}!peach.nn.nn.FeedForward.\_\_getbias \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_getbias}(\textit{self})

    \end{boxedminipage}

    \label{peach:nn:nn:FeedForward:__gety}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.FeedForward \textit{(class)}!peach.nn.nn.FeedForward.\_\_gety \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_gety}(\textit{self})

    \end{boxedminipage}

    \label{peach:nn:nn:FeedForward:__getphi}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.FeedForward \textit{(class)}!peach.nn.nn.FeedForward.\_\_getphi \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_getphi}(\textit{self})

    \end{boxedminipage}

    \label{peach:nn:nn:FeedForward:__setphi}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.FeedForward \textit{(class)}!peach.nn.nn.FeedForward.\_\_setphi \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_setphi}(\textit{self}, \textit{phis})

    \end{boxedminipage}

    \label{peach:nn:nn:FeedForward:__call__}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.FeedForward \textit{(class)}!peach.nn.nn.FeedForward.\_\_call\_\_ \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

The feedforward method of the network.

The \texttt{{\_}{\_}call{\_}{\_}} interface should be called if the answer of the neuron
network to a given input vector \texttt{x} is desired. \emph{This method has
collateral effects}, so beware. After the calling of this method, the
\texttt{y} property is set with the activation potential and the answer of
the neurons, respectivelly.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{x}

          \item[x]


The input vector to the network.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

      \textbf{Return Value}
      \begin{quote}

The vector containing the answer of every neuron in the last layer, in
the respective order.
      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{peach:nn:nn:FeedForward:learn}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.FeedForward \textit{(class)}!peach.nn.nn.FeedForward.learn \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{learn}(\textit{self}, \textit{x}, \textit{d})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

Applies one example of the training set to the network.

Using this method, one iteration of the learning procedure is made with
the neurons of this network. This method presents one example (not
necessarilly of a training set) and applies the learning rule over the
network. The learning rule is defined in the initialization of the
network, and some are implemented on the \texttt{lrules} method. New methods
can be created, consult the \texttt{lrules} documentation but, for
\texttt{FeedForward} instances, only \texttt{FFLearning} learning is allowed.

Also, notice that \emph{this method only applies the learning method!} The
network should be fed with the same input vector before trying to learn
anything first. Consult the \texttt{feed} and \texttt{train} methods below for
more ways to train a network.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{x}

          \item[x]


Input vector of the example. It should be a column vector of the
correct dimension, that is, the number of input neurons.
          \item[d]


The desired answer of the network for this particular input vector.
Notice that the desired answer should have the same dimension of the
last layer of the network. This means that a desired answer should
be given for every output of the network.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

      \textbf{Return Value}
      \begin{quote}

The error obtained by the network.
      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{peach:nn:nn:FeedForward:feed}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.FeedForward \textit{(class)}!peach.nn.nn.FeedForward.feed \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{feed}(\textit{self}, \textit{x}, \textit{d})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

Feed the network and applies one example of the training set to the
network.

Using this method, one iteration of the learning procedure is made with
the neurons of this network. This method presents one example (not
necessarilly of a training set) and applies the learning rule over the
network. The learning rule is defined in the initialization of the
network, and some are implemented on the \texttt{lrules} method. New methods
can be created, consult the \texttt{lrules} documentation but, for
\texttt{FeedForward} instances, only \texttt{FFLearning} learning is allowed.

Also, notice that \emph{this method feeds the network} before applying the
learning rule. Feeding the network has collateral effects, and some
properties change when this happens. Namely, the \texttt{y} property is set.
Please consult the \texttt{{\_}{\_}call{\_}{\_}} interface.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{x}

          \item[x]


Input vector of the example. It should be a column vector of the
correct dimension, that is, the number of input neurons.
          \item[d]


The desired answer of the network for this particular input vector.
Notice that the desired answer should have the same dimension of the
last layer of the network. This means that a desired answer should
be given for every output of the network.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

      \textbf{Return Value}
      \begin{quote}

The error obtained by the network.
      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{peach:nn:nn:FeedForward:train}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.FeedForward \textit{(class)}!peach.nn.nn.FeedForward.train \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{train}(\textit{self}, \textit{train\_set}, \textit{imax}=\texttt{2000}, \textit{emax}=\texttt{1e-05}, \textit{randomize}=\texttt{False})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

Presents a training set to the network.

This method automatizes the training of the network. Given a training
set, the examples are shown to the network (possibly in a randomized
way). A maximum number of iterations or a maximum admitted error should
be given as a stop condition.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{xxxxxxxxx}

          \item[train\_set]


The training set is a list of examples. It can have any size and can
contain repeated examples. In fact, the definition of the training
set is open. Each element of the training set, however, should be a
two-tuple \texttt{(x, d)}, where \texttt{x} is the input vector, and \texttt{d} is
the desired response of the network for this particular input. See
the \texttt{learn} and \texttt{feed} for more information.
          \item[imax]


The maximum number of iterations. Examples from the training set
will be presented to the network while this limit is not reached.
Defaults to 2000.
          \item[emax]


The maximum admitted error. Examples from the training set will be
presented to the network until the error obtained is lower than this
limit. Defaults to 1e-5.
          \item[randomize]


If this is \texttt{True}, then the examples are shown in a randomized
order. If \texttt{False}, then the examples are shown in the same order
that they appear in the \texttt{train{\_}set} list. Defaults to \texttt{False}.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__add__}
    \index{list.\_\_add\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_add\_\_}(\textit{x}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x+y
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__contains__}
    \index{list.\_\_contains\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_contains\_\_}(\textit{x}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

y in x
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__delattr__}
    \index{object.\_\_delattr\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_delattr\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x.{\_}{\_}delattr{\_}{\_}('name') {\textless}=={\textgreater} del x.name
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__delitem__}
    \index{list.\_\_delitem\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_delitem\_\_}(\textit{x}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

del x{[}y{]}
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__delslice__}
    \index{list.\_\_delslice\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_delslice\_\_}(\textit{x}, \textit{i}, \textit{j})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

del x{[}i:j{]}

Use of negative indices is not supported.
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__eq__}
    \index{list.\_\_eq\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_eq\_\_}(\textit{x}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x==y
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__ge__}
    \index{list.\_\_ge\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_ge\_\_}(\textit{x}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x{\textgreater}=y
    \vspace{1ex}

    \end{boxedminipage}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_getattribute\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x.{\_}{\_}getattribute{\_}{\_}('name') {\textless}=={\textgreater} x.name
    \vspace{1ex}

      Overrides: object.\_\_getattribute\_\_

    \end{boxedminipage}

    \label{list:__getitem__}
    \index{list.\_\_getitem\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_getitem\_\_}(\textit{x}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x{[}y{]}
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__getslice__}
    \index{list.\_\_getslice\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_getslice\_\_}(\textit{x}, \textit{i}, \textit{j})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x{[}i:j{]}

Use of negative indices is not supported.
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__gt__}
    \index{list.\_\_gt\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_gt\_\_}(\textit{x}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x{\textgreater}y
    \vspace{1ex}

    \end{boxedminipage}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_hash\_\_}(\textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

hash(x)
    \vspace{1ex}

      Overrides: object.\_\_hash\_\_

    \end{boxedminipage}

    \label{list:__iadd__}
    \index{list.\_\_iadd\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_iadd\_\_}(\textit{x}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x+=y
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__imul__}
    \index{list.\_\_imul\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_imul\_\_}(\textit{x}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x*=y
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__iter__}
    \index{list.\_\_iter\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_iter\_\_}(\textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

iter(x)
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__le__}
    \index{list.\_\_le\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_le\_\_}(\textit{x}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x{\textless}=y
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__len__}
    \index{list.\_\_len\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_len\_\_}(\textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

len(x)
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__lt__}
    \index{list.\_\_lt\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_lt\_\_}(\textit{x}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x{\textless}y
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__mul__}
    \index{list.\_\_mul\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_mul\_\_}(\textit{x}, \textit{n})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x*n
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__ne__}
    \index{list.\_\_ne\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_ne\_\_}(\textit{x}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x!=y
    \vspace{1ex}

    \end{boxedminipage}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_new\_\_}(\textit{T}, \textit{S}, \textit{...})

      \textbf{Return Value}
      \begin{quote}
\begin{alltt}
a new object with type S, a subtype of T
\end{alltt}

      \end{quote}

    \vspace{1ex}

      Overrides: object.\_\_new\_\_

    \end{boxedminipage}

    \label{object:__reduce__}
    \index{object.\_\_reduce\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_reduce\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

helper for pickle
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__reduce_ex__}
    \index{object.\_\_reduce\_ex\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_reduce\_ex\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

helper for pickle
    \vspace{1ex}

    \end{boxedminipage}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_repr\_\_}(\textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

repr(x)
    \vspace{1ex}

      Overrides: object.\_\_repr\_\_

    \end{boxedminipage}

    \label{list:__reversed__}
    \index{list.\_\_reversed\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_reversed\_\_}(\textit{L})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

return a reverse iterator over the list
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__rmul__}
    \index{list.\_\_rmul\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_rmul\_\_}(\textit{x}, \textit{n})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

n*x
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__setattr__}
    \index{object.\_\_setattr\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_setattr\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x.{\_}{\_}setattr{\_}{\_}('name', value) {\textless}=={\textgreater} x.name = value
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__setitem__}
    \index{list.\_\_setitem\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_setitem\_\_}(\textit{x}, \textit{i}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x{[}i{]}=y
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:__setslice__}
    \index{list.\_\_setslice\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_setslice\_\_}(\textit{x}, \textit{i}, \textit{j}, \textit{y})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x{[}i:j{]}=y

Use  of negative indices is not supported.
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__str__}
    \index{object.\_\_str\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_str\_\_}(\textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

str(x)
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:append}
    \index{list.append \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{append}(\textit{L}, \textit{object})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

append object to end
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:count}
    \index{list.count \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{count}(\textit{L}, \textit{value})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

return number of occurrences of value
    \vspace{1ex}

      \textbf{Return Value}
      \begin{quote}
\begin{alltt}
integer
\end{alltt}

      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{list:extend}
    \index{list.extend \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{extend}(\textit{L}, \textit{iterable})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

extend list by appending elements from the iterable
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:index}
    \index{list.index \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{index}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

L.index(value, {[}start, {[}stop{]}{]}) -{\textgreater} integer -{}- return first index of value
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:insert}
    \index{list.insert \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{insert}(\textit{L}, \textit{index}, \textit{object})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

insert object before index
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:pop}
    \index{list.pop \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{pop}(\textit{L}, \textit{index}=\texttt{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

remove and return item at index (default last)
    \vspace{1ex}

      \textbf{Return Value}
      \begin{quote}
\begin{alltt}
item
\end{alltt}

      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{list:remove}
    \index{list.remove \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{remove}(\textit{L}, \textit{value})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

remove first occurrence of value
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:reverse}
    \index{list.reverse \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{reverse}(\textit{L})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

reverse \emph{IN PLACE}
    \vspace{1ex}

    \end{boxedminipage}

    \label{list:sort}
    \index{list.sort \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{sort}(\textit{L}, \textit{cmp}=\texttt{None}, \textit{key}=\texttt{None}, \textit{reverse}=\texttt{False})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

stable sort \emph{IN PLACE};
cmp(x, y) -{\textgreater} -1, 0, 1
    \vspace{1ex}

    \end{boxedminipage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

\begin{longtable}{|p{.30\textwidth}|p{.62\textwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright n\-l\-a\-y\-e\-r\-s\- & \raggedright Number of layers of the neural network. Not writable.

\textbf{Value:} 
{\tt {\textless}property object at 0x8d164dc{\textgreater}}&\\
\cline{1-2}
\raggedright b\-i\-a\-s\- & \raggedright A tuple containing the bias of each layer. Not writable.

\textbf{Value:} 
{\tt {\textless}property object at 0x8d16504{\textgreater}}&\\
\cline{1-2}
\raggedright y\- & \raggedright A list of activation values for each neuron in the last layer of the
network, ie., the answer of the network. This property is available only
after the network is fed some input.

\textbf{Value:} 
{\tt {\textless}property object at 0x8d1652c{\textgreater}}&\\
\cline{1-2}
\raggedright p\-h\-i\- & \raggedright Activation functions for every layer in the network. It is a list of
\texttt{Activation} objects, but can be set with only one function. In this case,
the same function is used for every layer.

\textbf{Value:} 
{\tt {\textless}property object at 0x8d16554{\textgreater}}&\\
\cline{1-2}
\raggedright \_\-\_\-c\-l\-a\-s\-s\-\_\-\_\- & \raggedright \textbf{Value:} 
{\tt {\textless}attribute '\_\_class\_\_' of 'object' objects{\textgreater}}&\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.FeedForward \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.SOM \textit{(class)}|(}
\subsection{Class SOM}

    \label{peach:nn:nn:SOM}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.nn.base.Layer, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.nn.base.Layer}\multirow{2}{\BCL}{peach.nn.base.Layer}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.nn.nn.SOM}}
\end{tabular}


A Self-Organizing Map (SOM).

A self-organizing map is a type of neural network that is trained via
unsupervised learning. In particular, the self-organizing map finds the
neuron closest to an input vector -{}- this neuron is the winning neuron, and
it is the answer of the network. Thus, the SOM is usually used for
classification and pattern recognition.

The SOM is a single-layer network, so this class subclasses the \texttt{Layer}
class. But some of the properties of a \texttt{Layer} object are not available or
make no sense in this context.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{shape}, \textit{lrule}=\texttt{{\textless}class 'peach.nn.lrules.Competitive'{\textgreater}})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

Initializes a self-organizing map.

A self-organizing map is implemented as a layer of neurons. There is no
connection among the neurons. The answer to a given input is the neuron
closer to the given input. \texttt{phi} (the activation function) \texttt{v} (the
activation potential) and \texttt{bias} are not used.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{xxxxx}

          \item[shape]


Stablishes the size of the SOM. It must be a two-tuple of the
format \texttt{(m, n)}, where \texttt{m} is the number of neurons in the
layer, and \texttt{n} is the number of inputs of each neuron. The neurons
in the layer all have the same number of inputs.
          \item[lrule]


The learning rule used. Only \texttt{SOMLearning} objects (instances of
the class or of the subclasses) are allowed. Defaults to
\texttt{Competitive}. Check the \texttt{lrules} documentation for more
information.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

      Overrides: peach.nn.base.Layer.\_\_init\_\_

    \end{boxedminipage}

    \label{peach:nn:nn:SOM:__gety}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.SOM \textit{(class)}!peach.nn.nn.SOM.\_\_gety \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_gety}(\textit{self})

    \end{boxedminipage}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

The response of the network to a given input.

The \texttt{{\_}{\_}call{\_}{\_}} interface should be called if the answer of the neuron
network to a given input vector \texttt{x} is desired. \emph{This method has
collateral effects}, so beware. After the calling of this method, the
\texttt{y} property is set with the activation potential and the answer of
the neurons, respectivelly.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{x}

          \item[x]


The input vector to the network.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

      \textbf{Return Value}
      \begin{quote}

The winning neuron.
      \end{quote}

    \vspace{1ex}

      Overrides: peach.nn.base.Layer.\_\_call\_\_

    \end{boxedminipage}

    \label{peach:nn:nn:SOM:learn}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.SOM \textit{(class)}!peach.nn.nn.SOM.learn \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{learn}(\textit{self}, \textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

Applies one example of the training set to the network.

Using this method, one iteration of the learning procedure is made with
the neurons of this network. This method presents one example (not
necessarilly of a training set) and applies the learning rule over the
network. The learning rule is defined in the initialization of the
network, and some are implemented on the \texttt{lrules} method. New methods
can be created, consult the \texttt{lrules} documentation but, for
\texttt{SOM} instances, only \texttt{SOMLearning} learning is allowed.

Also, notice that \emph{this method only applies the learning method!} The
network should be fed with the same input vector before trying to learn
anything first. Consult the \texttt{feed} and \texttt{train} methods below for
more ways to train a network.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{x}

          \item[x]


Input vector of the example. It should be a column vector of the
correct dimension, that is, the number of input neurons.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

      \textbf{Return Value}
      \begin{quote}

The error obtained by the network.
      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{peach:nn:nn:SOM:feed}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.SOM \textit{(class)}!peach.nn.nn.SOM.feed \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{feed}(\textit{self}, \textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

Feed the network and applies one example of the training set to the
network.

Using this method, one iteration of the learning procedure is made with
the neurons of this network. This method presents one example (not
necessarilly of a training set) and applies the learning rule over the
network. The learning rule is defined in the initialization of the
network, and some are implemented on the \texttt{lrules} method. New methods
can be created, consult the \texttt{lrules} documentation but, for
\texttt{SOM} instances, only \texttt{SOMLearning} learning is allowed.

Also, notice that \emph{this method feeds the network} before applying the
learning rule. Feeding the network has collateral effects, and some
properties change when this happens. Namely, the \texttt{y} property is set.
Please consult the \texttt{{\_}{\_}call{\_}{\_}} interface.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{x}

          \item[x]


Input vector of the example. It should be a column vector of the
correct dimension, that is, the number of input neurons.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

      \textbf{Return Value}
      \begin{quote}

The error obtained by the network.
      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{peach:nn:nn:SOM:train}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.SOM \textit{(class)}!peach.nn.nn.SOM.train \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{train}(\textit{self}, \textit{train\_set}, \textit{imax}=\texttt{2000}, \textit{emax}=\texttt{1e-05}, \textit{randomize}=\texttt{False})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

Presents a training set to the network.

This method automatizes the training of the network. Given a training
set, the examples are shown to the network (possibly in a randomized
way). A maximum number of iterations or a maximum admitted error should
be given as a stop condition.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{xxxxxxxxx}

          \item[train\_set]


The training set is a list of examples. It can have any size and can
contain repeated examples. In fact, the definition of the training
set is open. Each element of the training set, however, should be a
input vector of the correct dimensions, See the \texttt{learn} and
\texttt{feed} for more information.
          \item[imax]


The maximum number of iterations. Examples from the training set
will be presented to the network while this limit is not reached.
Defaults to 2000.
          \item[emax]


The maximum admitted error. Examples from the training set will be
presented to the network until the error obtained is lower than this
limit. Defaults to 1e-5.
          \item[randomize]


If this is \texttt{True}, then the examples are shown in a randomized
order. If \texttt{False}, then the examples are shown in the same order
that they appear in the \texttt{train{\_}set} list. Defaults to \texttt{False}.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__delattr__}
    \index{object.\_\_delattr\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_delattr\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x.{\_}{\_}delattr{\_}{\_}('name') {\textless}=={\textgreater} del x.name
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__getattribute__}
    \index{object.\_\_getattribute\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_getattribute\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x.{\_}{\_}getattribute{\_}{\_}('name') {\textless}=={\textgreater} x.name
    \vspace{1ex}

    \end{boxedminipage}

    \label{peach:nn:base:Layer:__getitem__}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.base \textit{(module)}!peach.nn.base.Layer \textit{(class)}!peach.nn.base.Layer.\_\_getitem\_\_ \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_getitem\_\_}(\textit{self}, \textit{n})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

The \texttt{{[} {]}} get interface.

The input to this method is forwarded to the \texttt{weights} property. That
means that it will return the respective line/element of the weight
array.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{x}

          \item[n]


A slice object containing the elements referenced. Since it is
forwarded to an array, it behaves exactly as one.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

      \textbf{Return Value}
      \begin{quote}

The element or elements in the referenced indices.
      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__hash__}
    \index{object.\_\_hash\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_hash\_\_}(\textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

hash(x)
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__new__}
    \index{object.\_\_new\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_new\_\_}(\textit{T}, \textit{S}, \textit{...})

      \textbf{Return Value}
      \begin{quote}
\begin{alltt}
a new object with type S, a subtype of T
\end{alltt}

      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__reduce__}
    \index{object.\_\_reduce\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_reduce\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

helper for pickle
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__reduce_ex__}
    \index{object.\_\_reduce\_ex\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_reduce\_ex\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

helper for pickle
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__repr__}
    \index{object.\_\_repr\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_repr\_\_}(\textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

repr(x)
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__setattr__}
    \index{object.\_\_setattr\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_setattr\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x.{\_}{\_}setattr{\_}{\_}('name', value) {\textless}=={\textgreater} x.name = value
    \vspace{1ex}

    \end{boxedminipage}

    \label{peach:nn:base:Layer:__setitem__}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.base \textit{(module)}!peach.nn.base.Layer \textit{(class)}!peach.nn.base.Layer.\_\_setitem\_\_ \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_setitem\_\_}(\textit{self}, \textit{n}, \textit{w})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

The \texttt{{[} {]}} set interface.

The inputs to this method are forwarded to the \texttt{weights} property.
That means that it will set the respective line/element of the weight
array.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{x}

          \item[n]


A slice object containing the elements referenced. Since it is
forwarded to an array, it behaves exactly as one.
          \item[w]


A value or array of values to be set in the given indices.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__str__}
    \index{object.\_\_str\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_str\_\_}(\textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

str(x)
    \vspace{1ex}

    \end{boxedminipage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

\begin{longtable}{|p{.30\textwidth}|p{.62\textwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright y\- & \raggedright The winning neuron for a given input, the answer of the network. This
property is available only after the network is fed some input.

\textbf{Value:} 
{\tt {\textless}property object at 0x8d1661c{\textgreater}}&\\
\cline{1-2}
\raggedright \_\-\_\-c\-l\-a\-s\-s\-\_\-\_\- & \raggedright \textbf{Value:} 
{\tt {\textless}attribute '\_\_class\_\_' of 'object' objects{\textgreater}}&\\
\cline{1-2}
\raggedright b\-i\-a\-s\- & \raggedright True if the neuron is biased. Not writable.

\textbf{Value:} 
{\tt {\textless}property object at 0x8cf98ec{\textgreater}}&\\
\cline{1-2}
\raggedright i\-n\-p\-u\-t\-s\- & \raggedright Number of inputs for each neuron in the layer. Not writable.

\textbf{Value:} 
{\tt {\textless}property object at 0x8cf989c{\textgreater}}&\\
\cline{1-2}
\raggedright p\-h\-i\- & \raggedright The activation function. It can be set with an \texttt{Activation} instance or
a standard Python function. If a standard function is given, it must receive
a real value and return a real value that is the activation value of the
neuron. In that case, it is adjusted to work accordingly with the internals
of the layer.

\textbf{Value:} 
{\tt {\textless}property object at 0x8cf993c{\textgreater}}&\\
\cline{1-2}
\raggedright s\-h\-a\-p\-e\- & \raggedright Shape of the layer, given in the format of a tuple \texttt{(m, n)}, where
\texttt{m} is the number of neurons in the layer, and \texttt{n} is the number of
inputs in each neuron. Not writable.

\textbf{Value:} 
{\tt {\textless}property object at 0x8cf98c4{\textgreater}}&\\
\cline{1-2}
\raggedright s\-i\-z\-e\- & \raggedright Number of neurons in the layer. Not writable.

\textbf{Value:} 
{\tt {\textless}property object at 0x8cf9874{\textgreater}}&\\
\cline{1-2}
\raggedright v\- & \raggedright The activation potential of the neuron. Not writable, and only available
after the neuron is fed some input.

\textbf{Value:} 
{\tt {\textless}property object at 0x8cf9964{\textgreater}}&\\
\cline{1-2}
\raggedright w\-e\-i\-g\-h\-t\-s\- & \raggedright A \texttt{numpy} array containing the synaptic weights of the network. Each
line is the weight vector of a neuron. It is writable, but the new weight
array must be the same shape of the neuron, or an exception is raised.

\textbf{Value:} 
{\tt {\textless}property object at 0x8cf9914{\textgreater}}&\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}!peach.nn.nn.SOM \textit{(class)}|)}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.nn \textit{(module)}|)}

%
% API Documentation for Peach - Computational Intelligence for Python
% Module peach.optm.optm
%
% Generated by epydoc 3.0beta1
% [Mon Dec 21 08:51:38 2009]
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Module Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.optm \textit{(module)}|(}
\section{Module peach.optm.optm}

    \label{peach:optm:optm}

Basic definitons and base class for optimizers

This sub-package exports some auxiliary functions to work with cost functions,
namely, a function to calculate gradient vectors and hessian matrices, which are
extremely important in optimization.

Also, a base class, \texttt{Optimizer}, for all optimizers. Sub-class this class if
you want to create your own optmizer, and follow the interface. This will allow
easy configuration of your own scripts and comparison between methods.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               Functions                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsection{Functions}

    \label{peach:optm:optm:gradient}
    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.optm \textit{(module)}!peach.optm.optm.gradient \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{gradient}(\textit{f}, \textit{dx}=\texttt{1e-05})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

Creates a function that calculates the gradient vector of a scalar field.

This function takes as a parameter a scalar function and creates a new
function that is able to calculate the derivative (in case of single
variable functions) or the gradient vector (in case of multivariable
functions. Please, note that this function takes as a parameter a
\emph{function}, and returns as a result \emph{another function}. Calling the returned
function on a point will give the gradient vector of the original function
at that point:
\begin{quote}{\ttfamily \raggedright \noindent
>{}>{}>~def~f(x):~\\
~~~~~~~~return~x{\textasciicircum}2~\\
~\\
>{}>{}>~df~=~gradient(f)~\\
>{}>{}>~df(1)~\\
2
}\end{quote}

In the above example, \texttt{df} is a generated function which will return the
result of the expression \texttt{2*x}, the derivative of the original function.
In the case \texttt{f} is a multivariable function, it is assumed that its
argument is a line vector.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{xx}

          \item[f]


Any function, one- or multivariable. The function must be an scalar
function, though there is no checking at the moment the function is
created. If \texttt{f} is not an scalar function, an exception will be
raised at the moment the returned function is used.
          \item[dx]


Optional argument that gives the precision of the calculation. It is
recommended that \texttt{dx = sqrt(D)}, where \texttt{D} is the machine precision.
It defaults to \texttt{1e-5}, which usually gives a good estimate.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

      \textbf{Return Value}
      \begin{quote}

A new function which, upon calling, gives the derivative or gradient
vector of the original function on the analised point. The parameter of
the returned function is a real number or a line vector where the gradient
should be calculated.
      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{peach:optm:optm:hessian}
    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.optm \textit{(module)}!peach.optm.optm.hessian \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{hessian}(\textit{f}, \textit{dx}=\texttt{1e-05})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

Creates a function that calculates the hessian matrix of a scalar field.

This function takes as a parameter a scalar function and creates a new
function that is able to calculate the second derivative (in case of single
variable functions) or the hessian matrix (in case of multivariable
functions. Please, note that this function takes as a parameter a
\emph{function}, and returns as a result \emph{another function}. Calling the returned
function on a point will give the hessian matrix of the original function
at that point:
\begin{quote}{\ttfamily \raggedright \noindent
>{}>{}>~def~f(x):~\\
~~~~~~~~return~x{\textasciicircum}4~\\
~\\
>{}>{}>~ddf~=~hessian(f)~\\
>{}>{}>~ddf(1)~\\
12
}\end{quote}

In the above example, \texttt{ddf} is a generated function which will return the
result of the expression \texttt{12*x**2}, the second derivative of the original
function. In the case \texttt{f} is a multivariable function, it is assumed that
its argument is a line vector.
    \vspace{1ex}

      \textbf{Parameters}
      \begin{quote}
        \begin{Ventry}{xx}

          \item[f]


Any function, one- or multivariable. The function must be an scalar
function, though there is no checking at the moment the function is
created. If \texttt{f} is not an scalar function, an exception will be
raised at the moment the returned function is used.
          \item[dx]


Optional argument that gives the precision of the calculation. It is
recommended that \texttt{dx = sqrt(D)}, where \texttt{D} is the machine precision.
It defaults to \texttt{1e-5}, which usually gives a good estimate.
        \end{Ventry}

      \end{quote}

    \vspace{1ex}

      \textbf{Return Value}
      \begin{quote}

A new function which, upon calling, gives the second derivative or hessian
matrix of the original function on the analised point. The parameter of
the returned function is a real number or a line vector where the hessian
should be calculated.
      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               Variables                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsection{Variables}

\begin{longtable}{|p{.30\textwidth}|p{.62\textwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright \_\-\_\-d\-o\-c\-\_\-\_\- & \raggedright \textbf{Value:} 
{\tt \texttt{...}}&\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.optm \textit{(module)}!peach.optm.optm.Optimizer \textit{(class)}|(}
\subsection{Class Optimizer}

    \label{peach:optm:optm:Optimizer}
\begin{tabular}{cccccc}
% Line for object, linespec=[False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
  \\
&&\multicolumn{2}{l}{\textbf{peach.optm.optm.Optimizer}}
\end{tabular}

\textbf{Known Subclasses:}
peach.optm.stochastic.CrossEntropy,
    peach.optm.quasinewton.BFGS,
    peach.optm.quasinewton.DFP,
    peach.optm.quasinewton.SR1,
    peach.optm.multivar.Direct,
    peach.optm.multivar.Gradient,
    peach.optm.multivar.Newton,
    peach.optm.linear.Direct1D,
    peach.optm.linear.Fibonacci,
    peach.optm.linear.GoldenRule,
    peach.optm.linear.Interpolation,
    peach.optm.sa.ContinuousSA,
    peach.optm.sa.DiscreteSA


Base class for all optimizers.

This class does nothing, and shouldn't be instantiated. Its only purpose is
to serve as a template (or interface) to implemented optimizers. To create
your own optimizer, subclass this.

This class defines 3 methods that should be present in any subclass. They
are defined here:
\begin{quote}
\begin{description}
%[visit_definition_list_item]
\item[{{\_}{\_}init{\_}{\_}}] %[visit_definition]

Initializes the optimizer. There are three usual parameters in this
method, which signature should be:
\begin{quote}{\ttfamily \raggedright \noindent
{\_}{\_}init{\_}{\_}(self,~f,~...,~emax=1e-8,~imax=1000)
}\end{quote}
\begin{description}
%[visit_definition_list_item]
\item[{where:}] %[visit_definition]
\begin{itemize}
\item {} 
\texttt{f} is the cost function to be minimized;

\item {} 
\texttt{...} represent additional configuration of the optimizer, and it
is dependent of the technique implemented;

\item {} 
\texttt{emax} is the maximum allowed error. The default value above is
only a suggestion;

\item {} 
\texttt{imax} is the maximum number of iterations of the method. The
default value above is only a suggestions.

\end{itemize}

%[depart_definition]
%[depart_definition_list_item]
\end{description}

%[depart_definition]
%[depart_definition_list_item]
%[visit_definition_list_item]
\item[{step}] %[visit_definition]

This method should take an estimate and calculate the next, possibly
better, estimate. Notice that the next estimate is strongly dependent of
the method, the optimizer state and configuration, and two calls to this
method with the same estimate might not give the same results. The
method signature is:
\begin{quote}{\ttfamily \raggedright \noindent
step(self,~x)
}\end{quote}

and the implementation should keep track of all the needed parameters.
The method should return a tuple \texttt{(x, e)} with the new estimate of the
solution and the estimate of the error.

%[depart_definition]
%[depart_definition_list_item]
%[visit_definition_list_item]
\item[{{\_}{\_}call{\_}{\_}}] %[visit_definition]

This method should take an estimate and iterate the optimizer until one
of the stop criteria is met: either less than the maximum error or more
than the maximum number of iterations. Error is usually calculated as an
estimate using the previous estimate, but any technique might be used.
Use a counter to keep track of the number of iterations. The method
signature is:
\begin{quote}{\ttfamily \raggedright \noindent
{\_}{\_}call{\_}{\_}(self,~x)
}\end{quote}

and the implementation should keep track of all the needed parameters.
The method should return a tuple \texttt{(x, e)} with the final estimate of
the solution and the estimate of the error.

%[depart_definition]
%[depart_definition_list_item]
\end{description}
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \label{peach:optm:optm:Optimizer:__call__}
    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.optm \textit{(module)}!peach.optm.optm.Optimizer \textit{(class)}!peach.optm.optm.Optimizer.\_\_call\_\_ \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{x})

    \end{boxedminipage}

    \label{object:__delattr__}
    \index{object.\_\_delattr\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_delattr\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x.{\_}{\_}delattr{\_}{\_}('name') {\textless}=={\textgreater} del x.name
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__getattribute__}
    \index{object.\_\_getattribute\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_getattribute\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x.{\_}{\_}getattribute{\_}{\_}('name') {\textless}=={\textgreater} x.name
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__hash__}
    \index{object.\_\_hash\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_hash\_\_}(\textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

hash(x)
    \vspace{1ex}

    \end{boxedminipage}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{f}=\texttt{None}, \textit{emax}=\texttt{1e-08}, \textit{imax}=\texttt{1000})


x.{\_}{\_}init{\_}{\_}(...) initializes x; see x.{\_}{\_}class{\_}{\_}.{\_}{\_}doc{\_}{\_} for signature
    \vspace{1ex}

      Overrides: object.\_\_init\_\_ 	extit{(inherited documentation)}

    \end{boxedminipage}

    \label{object:__new__}
    \index{object.\_\_new\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_new\_\_}(\textit{T}, \textit{S}, \textit{...})

      \textbf{Return Value}
      \begin{quote}
\begin{alltt}
a new object with type S, a subtype of T
\end{alltt}

      \end{quote}

    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__reduce__}
    \index{object.\_\_reduce\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_reduce\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

helper for pickle
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__reduce_ex__}
    \index{object.\_\_reduce\_ex\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_reduce\_ex\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

helper for pickle
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__repr__}
    \index{object.\_\_repr\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_repr\_\_}(\textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

repr(x)
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__setattr__}
    \index{object.\_\_setattr\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_setattr\_\_}(\textit{...})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

x.{\_}{\_}setattr{\_}{\_}('name', value) {\textless}=={\textgreater} x.name = value
    \vspace{1ex}

    \end{boxedminipage}

    \label{object:__str__}
    \index{object.\_\_str\_\_ \textit{(function)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{\_\_str\_\_}(\textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}

str(x)
    \vspace{1ex}

    \end{boxedminipage}

    \label{peach:optm:optm:Optimizer:step}
    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.optm \textit{(module)}!peach.optm.optm.Optimizer \textit{(class)}!peach.optm.optm.Optimizer.step \textit{(method)}}

    \vspace{0.5ex}

    \begin{boxedminipage}{\textwidth}

    \raggedright \textbf{step}(\textit{self}, \textit{x})

    \end{boxedminipage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

\begin{longtable}{|p{.30\textwidth}|p{.62\textwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright \_\-\_\-c\-l\-a\-s\-s\-\_\-\_\- & \raggedright \textbf{Value:} 
{\tt {\textless}attribute '\_\_class\_\_' of 'object' objects{\textgreater}}&\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.optm \textit{(module)}!peach.optm.optm.Optimizer \textit{(class)}|)}
    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.optm \textit{(module)}|)}
